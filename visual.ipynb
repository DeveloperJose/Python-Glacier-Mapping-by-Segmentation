{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "from addict import Dict\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage import color\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import seaborn_image as isns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import Image\n",
    "\n",
    "from segmentation.model.metrics import *\n",
    "from segmentation.model.frame import Framework\n",
    "import segmentation.model.functions as fn\n",
    "import segmentation.data.slice as sl\n",
    "\n",
    "isns.set_context(\"notebook\")\n",
    "\n",
    "def min_max(im):\n",
    "    return (im - im.min()) / im.max()\n",
    "\n",
    "def mean_std(im):\n",
    "    return (im - im.mean()) / im.std()\n",
    "\n",
    "def get_tp_fp_fn(pred, true):\n",
    "    pred, true = torch.from_numpy(pred), torch.from_numpy(true)\n",
    "    tp, fp, fn = tp_fp_fn(pred, true)\n",
    "    return tp, fp, fn\n",
    "\n",
    "def get_precision_recall_iou(tp, fp, fn):\n",
    "    p, r, i = precision(tp, fp, fn), recall(tp, fp, fn), IoU(tp, fp, fn)\n",
    "    return p, r, i\n",
    "\n",
    "#%% Data Preparation\n",
    "conf = Dict(yaml.safe_load(open('./conf/unet_predict.yaml')))\n",
    "conf.model_opts_cleanice.args.inchannels = len(conf.use_channels_cleanice)\n",
    "conf.model_opts_cleanice.args.outchannels = len(conf.class_names)\n",
    "use_physics = 10 in conf.use_channels_cleanice\n",
    "\n",
    "data_dir = pathlib.Path(conf.data_dir)\n",
    "preds_dir = pathlib.Path(conf.out_processed_dir) / \"preds\" / conf.run_name\n",
    "model_path = pathlib.Path(conf.folder_name) / conf.run_name / 'models' / 'model_best.pt'\n",
    "loss_fn = fn.get_loss(conf.model_opts_cleanice.args.outchannels)\n",
    "frame = Framework(\n",
    "    loss_fn=loss_fn,\n",
    "    model_opts=conf.model_opts_cleanice,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    device=(int(conf.gpu_rank))\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    state_dict = torch.load(model_path)\n",
    "else:\n",
    "    state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "frame.load_state_dict(state_dict)\n",
    "\n",
    "arr = np.load(data_dir / \"normalize_train.npy\")\n",
    "if conf.normalize == \"mean-std\":\n",
    "    _mean, _std = arr[0], arr[1]\n",
    "if conf.normalize == \"min-max\":\n",
    "    _min, _max = arr[2], arr[3]\n",
    "\n",
    "files = os.listdir(data_dir / \"test\")\n",
    "inputs = [x for x in files if \"tiff\" in x]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data\n",
    "Use this widget to visualize the testing set images and labels as well as the model predictions and how where exactly they differ from the labeled ground truth.\n",
    "\n",
    "For the disagreements:\n",
    "* If the color is **RED** that means the label says those pixels are the given class but the model predicted otherwise.\n",
    "* If the color is **BLUE** that means the model says those pixels are the given class but the labeled ground truth says otherwise.\n",
    "* If you enable the input \"visualize_agreement\" then **GREEN** will be used to represent the pixels where both the model and label agree.\n",
    "\n",
    "Here is an explanation of all the inputs:\n",
    "\n",
    "> x_fname\n",
    "* Filename in the format \"tiff_X_slice_Y.npy\" where X=Cell Number (0 to 201) and Y=Slice Number\n",
    "\n",
    "> Channel 1, 2, and 3\n",
    "* The channels used to create the false color image.\n",
    "\n",
    "> color_map\n",
    "* The map used to determine how to color the grayscale images https://matplotlib.org/stable/gallery/color/colormap_reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f676250f18354727a1c30f26d682bedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x_fname', options=('tiff_7_slice_11.npy', 'tiff_14_slice_0.npy', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "labels = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6_VCID1\", \"B6_VCID2\", \"B7\", \"elevation\", \"slope\"]\n",
    "labels_with_idx = [(name, idx) for idx, name in enumerate(labels)]\n",
    "\n",
    "ch1 = widgets.Dropdown(options=labels_with_idx, value=2, description='Channel 1')\n",
    "ch2 = widgets.Dropdown(options=labels_with_idx, value=1, description='Channel 2')\n",
    "ch3 = widgets.Dropdown(options=labels_with_idx, value=0, description='Channel 3')\n",
    "\n",
    "@interact_manual\n",
    "def show_data(x_fname = inputs, ch1=ch1, ch2=ch2, ch3=ch3, color_map=plt.colormaps(), figure_size=(1, 25), visualize_agreement=False):\n",
    "    # Load input image (x)\n",
    "    x = np.load(data_dir / \"test\" / x_fname)\n",
    "    im = x[:, :, [ch1, ch2, ch3]]\n",
    "    im = min_max(im)*255\n",
    "    im = im.astype(np.uint8)\n",
    "\n",
    "    if conf.normalize == \"mean-std\":\n",
    "        if use_physics:\n",
    "            x[:, :, :-1] = (x[:, :, :-1] - _mean[:-1]) / _std[:-1]\n",
    "        else:\n",
    "            x = (x - _mean) / _std\n",
    "    if conf.normalize == \"min-max\":\n",
    "        x = (x - _min) / (_max - _min)\n",
    "\n",
    "    # Load label (y)\n",
    "    mask = np.sum(x, axis=2) == 0\n",
    "    has_mask = np.sum(mask==1) > 0\n",
    "    print(has_mask)\n",
    "    y_fname = x_fname.replace(\"tiff\", \"mask\")\n",
    "    y_true = np.load(data_dir / \"test\" / y_fname)+1\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true[mask] = 0\n",
    "\n",
    "    # Visualize False Color\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(2*figure_size, 2*figure_size))\n",
    "    g = isns.imgplot(ax=ax[0], data=im)\n",
    "    ax[0].set_title('False Color Image')\n",
    "\n",
    "    # Visualize Label\n",
    "    ticks = [0, 1, 2, 3] if has_mask else [1, 2, 3]\n",
    "    g = isns.imgplot(ax=ax[1], data=y_true, cmap=color_map, cbar_ticks=ticks)\n",
    "    ax[1].set_title('Labels (0=Mask, 1=BG, 2=CI, 3=Debris)')\n",
    "\n",
    "    # Visualize Physics Channel\n",
    "    phys_channel = min_max(x[:, :, 10])\n",
    "    g = isns.imgplot(ax=ax[2], data=phys_channel, cmap=color_map)\n",
    "    ax[2].set_title(f'Physics Channel')\n",
    "\n",
    "    # Visualize Mask\n",
    "    g = isns.imgplot(ax=ax[3], data=mask, cmap=color_map)\n",
    "    ax[3].set_title(f'Mask')\n",
    "\n",
    "    # Visualize Landsat7 Bands\n",
    "    g = isns.ImageGrid(x, cmap=color_map, stop=10, col_wrap=5, height=figure_size, cbar_label=labels, despine=True)\n",
    "\n",
    "    #%% ********** PREDICTION TIME! **********\n",
    "    # Send input to model to get predicted labels\n",
    "    _x = torch.from_numpy(np.expand_dims(x[:,:,conf.use_channels_cleanice], axis=0)).float()\n",
    "    pred = frame.infer(_x)\n",
    "    pred = torch.nn.Softmax(3)(pred)\n",
    "    pred = np.squeeze(pred.cpu())\n",
    "\n",
    "    # Threshold and fill holes for each class\n",
    "    _bg = pred[:, :, 0] >= conf.threshold[0]\n",
    "    _bg = binary_fill_holes(_bg)\n",
    "    _ci = pred[:, :, 1] >= conf.threshold[1]\n",
    "    _ci = binary_fill_holes(_ci)\n",
    "    _debris = pred[:, :, 2] >= conf.threshold[2]\n",
    "    _debris = binary_fill_holes(_debris)\n",
    "    \n",
    "    # Combine predictions once again\n",
    "    _pred = np.zeros((pred.shape[0], pred.shape[1]), dtype=np.uint8)\n",
    "    _pred[:] = 1\n",
    "\n",
    "    _pred[_bg] = 1\n",
    "    _pred[_ci] = 2\n",
    "    _pred[_debris] = 3\n",
    "    _pred[mask] = 0\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(3*figure_size, 2*figure_size))\n",
    "    g = isns.imgplot(ax=ax[1, 0], data=y_true, cmap=color_map, cbar_ticks=ticks)\n",
    "    ax[1, 0].set_title('Labels (0=Mask, 1=BG, 2=CI, 3=Debris)')\n",
    "\n",
    "    g = isns.imgplot(ax=ax[1, 1], data=im)\n",
    "    ax[1, 1].set_title('False Color Image')\n",
    "\n",
    "    g = isns.imgplot(ax=ax[1, 2], data=_pred, cmap=color_map, cbar_ticks=ticks)\n",
    "    ax[1, 2].set_title('Prediction (0=Mask, 1=BG, 2=CI, 3=Debris)')\n",
    "    print(np.unique(y_true), np.unique(_pred), np.sum(_pred==0))\n",
    "    # fig.suptitle('Label vs Prediction Disagreements (Red=Label, Blue=Prediction)')\n",
    "    for idx, (class_name, class_label) in enumerate([('BG', 1), ('CleanIce', 2), ('Debris', 3)]):\n",
    "        # Zero out everything in our label (y_true) that isn't the current class\n",
    "        class_only_true = y_true.copy()\n",
    "        class_only_true[class_only_true!=class_label] = 0\n",
    "\n",
    "        # Zero out everything in our prediction (_pred) that isn't the current class\n",
    "        class_only_pred = _pred.copy()\n",
    "        class_only_pred[class_only_pred!=class_label] = 0\n",
    "\n",
    "        # Color the disagreements\n",
    "        disagreements = np.zeros((class_only_true.shape[0], class_only_true.shape[1], 3), dtype=np.float32)\n",
    "        disagreements[np.logical_and(class_only_true==class_label, class_only_pred!=class_label)] = [1, 0, 0]\n",
    "        disagreements[np.logical_and(class_only_true!=class_label, class_only_pred==class_label)] = [0, 0, 1]\n",
    "\n",
    "        # Create an overlay for the disagreements\n",
    "        alphas = np.zeros_like(class_only_true, dtype=np.float32)\n",
    "        alphas[class_only_true!=class_only_pred] = 0.5\n",
    "        if visualize_agreement:\n",
    "            m = np.logical_and(class_only_true==class_only_pred, class_only_true==class_label)\n",
    "            disagreements[m] = [0, 1, 0]\n",
    "            alphas[m] = 0.5\n",
    "        im_overlay = np.dstack((disagreements, alphas))\n",
    "\n",
    "        # Visualize false color image with overlay\n",
    "        g = isns.imgplot(ax=ax[0, idx], data=im)\n",
    "        g = isns.imgplot(ax=ax[0, idx], data=im_overlay)\n",
    "        ax[0, idx].set_title(f'Red pixels -> TrueLabel={class_name} but model disagrees\\nBlue pixels -> Prediction={class_name} but label disagrees\\nGreen pixels -> Agreement')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
